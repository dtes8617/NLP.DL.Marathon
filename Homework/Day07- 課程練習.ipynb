{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Module\n",
    "* Base class for all neural network modules\n",
    "* 只要在nn.Module的子類中定義了forward函數，backward函數就會被自動實現（利用Autograd）\n",
    "* nn.Conv2d 本身也是nn.Module的類別(此時我們可以先不用理解nn.Conv2D做了什麼，只需了解其包含一些參數與操作)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 實踐 forward propagation \n",
    "* 為什麼不應該直接call model.forward : https://discuss.pytorch.org/t/any-different-between-model-input-and-model-forward-input/3690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.randn(1,1,124,124)\n",
    "output = model(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看 model 底下的 modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model.modules 遞迴的列出所有的 modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      ")\n",
      "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "for module in model.modules():\n",
    "    print(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model.children 只列出第一層的子 modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "for module in model.children():\n",
    "    print(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看 model 內的 parameters (torch.nn.parameter.Parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .named_parameters\n",
    "* named_parameters會列出每個nn.Module底下parameters 的名字,數值\n",
    "* 同時可以查看 requires_grad是否開啟(for backpropagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight True\n",
      "conv1.bias True\n",
      "conv2.weight True\n",
      "conv2.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name,param.requires_grad)\n",
    "    #param.requires_grad=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .parameters\n",
    "* 不會印出名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20, 1, 5, 5]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20, 20, 5, 5]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20]) True\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(type(param),param.shape, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 計算模型可訓練參數總量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總共參數量： 10540\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('總共參數量：' ,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.randn(1,1,124,124)\n",
    "output = model(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 確認 requires_grad為 True (default 就是 True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight True\n",
      "conv1.bias True\n",
      "conv2.weight True\n",
      "conv2.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 此時還沒做backpropagation，parameters沒有gradient value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 執行backward，完成後就能看到每個parameters底下的gradient value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.6210e+02,  5.1225e+02, -2.1730e+02, -4.5927e+01,  7.6519e+02],\n",
      "          [-8.3639e+02,  1.4350e+03, -4.9346e+02,  1.0653e+03, -9.7021e+02],\n",
      "          [-1.4194e+03,  7.7866e+02,  1.3832e+03, -1.1798e+03,  2.2985e+02],\n",
      "          [-1.0582e+03, -7.7341e+02,  2.5269e+02,  5.5109e+02,  1.4927e+02],\n",
      "          [ 3.2955e+02,  1.3545e+02,  1.7758e+01,  2.4372e+02, -1.0246e+03]]],\n",
      "\n",
      "\n",
      "        [[[-2.7771e+02,  2.8576e+02,  2.7087e+02, -2.3264e+02,  2.6199e+02],\n",
      "          [ 3.0646e+02,  2.8792e+02,  2.1235e+02, -5.2904e+02,  1.9815e+02],\n",
      "          [-4.4810e+02,  2.1456e+02,  1.7090e+02, -1.6141e+02, -2.8268e+02],\n",
      "          [ 1.2011e+02, -4.2804e+02,  8.5065e+01,  3.2301e+02, -2.2653e+02],\n",
      "          [ 4.1278e+02,  1.6778e+01, -2.2901e+02, -8.4452e+01, -1.4430e+02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6949e+01, -5.0699e+02, -3.0705e+02, -2.8467e+02, -4.0673e+02],\n",
      "          [-1.4856e+01,  3.6041e+02, -1.6105e+02,  2.8540e+02, -2.9854e+02],\n",
      "          [-1.8193e+02, -7.3799e+02, -3.7101e+02, -2.9654e+02, -7.7091e+01],\n",
      "          [-2.9044e+01,  2.9097e+02, -2.9090e+02,  2.9955e+02, -5.7916e+02],\n",
      "          [ 3.9724e+02,  3.7636e+02, -6.6949e+02, -3.9164e+02,  1.0752e+02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3697e+02,  3.9290e+02,  5.7983e+01,  6.5538e+01,  2.4719e+02],\n",
      "          [ 6.5384e+02, -2.9845e+02, -4.4245e+02,  5.1314e+02, -7.9123e+02],\n",
      "          [ 1.0161e+02,  3.1066e+02,  1.2639e+02, -7.6128e+02, -2.6191e+02],\n",
      "          [-6.8130e+01,  2.2623e+02,  1.3514e+02,  2.1071e+02, -3.0520e+02],\n",
      "          [ 1.1549e+02, -4.4490e+01, -7.0599e+02, -4.6459e+02, -1.4547e+02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.5146e+02, -1.0240e+03, -5.6606e+02, -2.3839e+02,  1.1893e+03],\n",
      "          [-1.4910e+03, -1.1688e+03,  8.5898e+02, -1.1131e+03,  1.2430e+02],\n",
      "          [-6.4129e+02,  1.3269e+03,  1.0876e+03,  9.1003e+02,  9.4201e+02],\n",
      "          [ 1.0126e+02,  1.0929e+03,  9.1323e+02,  5.3217e+02, -4.4278e+02],\n",
      "          [ 1.3425e+03, -1.3542e+03,  1.2449e+03,  5.6007e+02,  1.2118e+03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8748e+02, -3.2108e+02,  5.9260e+01, -4.3151e+02,  9.8896e+02],\n",
      "          [-2.2547e+02, -1.1601e+02,  8.6204e+00, -6.4074e+02,  3.8712e+02],\n",
      "          [-4.7056e+02, -8.8055e+02, -3.7523e+02,  1.8642e+02, -8.0691e+02],\n",
      "          [ 4.3967e+02,  6.7656e+02,  5.3949e+02, -1.2964e+02, -8.9552e+02],\n",
      "          [-5.7267e+02,  9.8078e+02,  5.0726e+02,  5.0576e+02,  4.0591e+02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0286e+02, -1.8653e+02,  4.5629e+02, -2.2371e+02,  3.8501e+02],\n",
      "          [ 1.6122e+02,  1.8702e+02, -2.8332e+02,  4.8064e+02, -3.1984e+02],\n",
      "          [-1.3429e+02, -3.0804e+02,  5.3225e+02,  3.9501e+02, -5.2502e+02],\n",
      "          [-1.2338e+02, -2.5423e+02, -3.8038e+02,  7.1762e+02,  5.2091e+02],\n",
      "          [ 5.1183e+01, -2.3880e+02,  5.5584e+01,  6.8972e+01,  4.3087e+02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0158e+03, -6.3603e+02, -1.2336e+03, -5.9078e+02,  7.5461e+02],\n",
      "          [-6.4652e+02, -2.7982e+01, -9.3678e+02,  5.8188e+02,  9.5317e+02],\n",
      "          [ 3.6620e+02,  2.8334e+00,  9.3004e+02,  4.4728e+01,  1.2039e+02],\n",
      "          [ 2.2031e+02,  9.1621e+02,  1.3034e+03,  3.4227e+02,  1.2441e+01],\n",
      "          [-1.1946e+03,  1.4399e+03, -7.4662e+02, -1.3787e+03,  1.0965e+03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1832e+03, -2.0939e+02, -1.4335e+02, -6.5192e+02,  1.7180e+03],\n",
      "          [-1.4416e+03, -1.9145e+02,  9.2659e+01,  2.1711e+01,  5.6037e+02],\n",
      "          [ 5.5936e+02, -2.0031e+03, -1.0167e+03,  3.6553e+02, -5.1124e+01],\n",
      "          [ 1.6924e+03, -3.8623e+02, -7.5620e+02, -5.2235e+02, -1.6612e+03],\n",
      "          [ 1.3859e+03, -1.1002e+03, -1.1571e+03, -1.4839e+03,  1.8015e+03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6349e+02, -3.3530e+02, -6.4267e+02, -1.1369e+02, -6.7395e+02],\n",
      "          [-6.8902e+02,  1.8908e+02,  3.7984e+01,  5.0925e+02,  3.0793e+02],\n",
      "          [-5.9807e+02,  5.3560e+02,  1.0310e+03, -6.7427e+02,  5.8783e+02],\n",
      "          [-1.3248e+03,  4.3049e+01,  6.8575e+02, -6.2278e+02, -1.5353e+03],\n",
      "          [-7.1419e+02,  1.1332e+01, -3.7783e+02, -1.4308e+03,  9.2071e+02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0979e+02,  3.6862e+02, -1.1018e+03,  8.0622e+02,  8.6763e+01],\n",
      "          [-3.2915e+02,  8.3991e+02,  2.4884e+02, -1.2422e+03, -2.1561e+02],\n",
      "          [-4.9239e+02,  5.9812e+02,  6.6086e+02, -2.4196e+02, -6.5297e+02],\n",
      "          [ 6.2019e+02, -1.0090e+02, -8.6224e+02,  5.0592e+02, -1.1665e+02],\n",
      "          [-5.4233e+02,  2.2735e+02, -5.0953e+02,  1.0553e+02,  8.0278e+02]]],\n",
      "\n",
      "\n",
      "        [[[-6.3249e+02,  2.1565e+02, -1.0695e+02, -3.4246e+02, -5.0318e+02],\n",
      "          [-5.5599e+02,  3.3624e+02,  1.0123e+03,  5.1530e+02,  3.6669e+02],\n",
      "          [-4.5153e+02, -1.7036e+02, -4.2747e+02,  3.4769e+02, -4.5796e+02],\n",
      "          [-3.2234e+02,  3.6602e+02,  2.1027e+02, -8.3983e+02,  3.9673e+02],\n",
      "          [ 5.1132e+02,  3.4768e+02, -5.8116e+02, -3.2773e+02, -6.7123e+01]]],\n",
      "\n",
      "\n",
      "        [[[-8.1367e+02,  2.9517e+02, -2.1243e+02,  3.9968e+02,  5.3042e+02],\n",
      "          [ 8.5409e+02,  9.9978e+02, -2.9909e+02,  6.9104e+02, -3.9574e+02],\n",
      "          [ 4.1686e+02,  7.6391e+02, -4.8874e+02, -2.1311e+02, -4.9675e+02],\n",
      "          [-2.1974e+02,  4.8507e+02, -6.8467e+01,  6.6063e+02,  5.8829e+02],\n",
      "          [-6.7935e+01,  5.6584e+02,  4.0522e+02,  1.1758e+03,  7.3193e+02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3127e+01, -2.1766e+02,  4.8196e+02, -3.3606e+02,  5.5488e+02],\n",
      "          [ 4.2415e+02,  2.3213e+02, -9.0659e+01,  1.2827e+02,  4.6798e+02],\n",
      "          [ 4.0080e+01, -9.6171e+02,  9.2673e+02,  7.6816e+02,  7.5272e+02],\n",
      "          [-7.4271e+02,  5.4339e+01, -3.7568e+02, -6.5829e+02, -4.5057e+02],\n",
      "          [ 3.6457e+02, -4.9683e+01,  5.1499e+02, -5.2993e+02, -1.3358e+02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2258e+02, -8.8780e+01, -8.5097e+00,  1.0498e+01, -3.8534e+02],\n",
      "          [-6.2414e+02, -1.1807e+02,  6.3491e+02,  1.0300e+02, -7.2787e+01],\n",
      "          [-2.9778e+02, -1.3769e+02, -6.0719e+02, -1.4498e+02,  1.5465e+02],\n",
      "          [ 2.1535e+01,  4.6187e+02,  1.8569e+02, -2.0300e+02, -2.4898e+02],\n",
      "          [ 9.1037e+01, -2.0031e+02,  1.2612e+02, -1.7012e+01, -1.9867e+02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2707e+03,  7.7032e+02, -9.4234e+02, -5.7473e+02, -2.0644e+02],\n",
      "          [ 2.3243e+02, -1.1859e+03, -8.3070e+02, -1.1302e+03,  5.0923e+02],\n",
      "          [-1.4573e+03,  5.9901e+02,  1.0978e+03,  9.7416e+02, -1.4213e+03],\n",
      "          [ 1.2969e+03,  4.2494e+02, -6.5904e+02, -4.7216e+02,  1.2579e+03],\n",
      "          [ 2.4380e+02,  5.4732e+02,  8.4754e+02,  6.2804e+02,  5.4286e+02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9705e+02,  1.1177e+03,  1.0216e+03,  4.5470e+02, -4.4552e+02],\n",
      "          [-1.3875e+02,  7.5281e+02,  4.1868e+02,  8.9262e+01, -3.5303e+02],\n",
      "          [ 2.4477e+02, -4.1370e+02,  1.0393e+03, -6.8033e+02,  5.9719e+02],\n",
      "          [ 5.6236e+01,  7.1066e+02,  1.0286e+02, -1.0059e+03, -6.7301e+01],\n",
      "          [ 9.8269e+02,  7.9167e+02,  1.4087e+03,  1.1652e+03, -1.2389e+03]]],\n",
      "\n",
      "\n",
      "        [[[-4.5072e+02, -3.6369e+02,  1.9273e+02,  3.3119e+02, -6.0469e+01],\n",
      "          [-6.0796e+02, -6.2105e+02,  1.0448e+02, -3.9405e+02,  2.8994e+02],\n",
      "          [ 9.3549e+01, -1.6197e+02, -4.0138e+02,  2.8502e+02, -3.7799e+02],\n",
      "          [ 1.3095e+02, -3.7065e+02, -4.4810e+02, -2.3911e+02,  3.7147e+01],\n",
      "          [-5.4306e+02, -2.2168e+01, -2.6923e+02,  1.8426e-01,  3.8651e+02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5355e+03, -8.8481e+02, -5.0198e+02,  1.0995e+03,  3.3900e+02],\n",
      "          [ 6.6876e+02,  6.2569e+02,  1.2653e+03, -1.0536e+03, -2.4793e+02],\n",
      "          [ 9.6427e+02, -4.7806e+02,  1.5112e+03, -8.0042e+02, -1.7662e+03],\n",
      "          [ 1.0260e+03, -1.0361e+03,  3.8669e+01, -1.1810e+03, -1.9162e+03],\n",
      "          [ 2.2241e+02, -7.8320e+02,  2.9281e+02,  3.3158e+02,  1.5312e+03]]],\n",
      "\n",
      "\n",
      "        [[[-3.7682e+02,  1.7059e+02,  2.7995e+02,  2.2532e+01, -1.9230e+02],\n",
      "          [-1.1717e+02,  6.0615e+01,  8.5552e+00, -1.5206e+02, -1.6703e+02],\n",
      "          [ 2.4411e+02,  7.8148e+01, -9.0429e+01, -3.0567e+00,  7.6895e+01],\n",
      "          [ 2.5793e+02, -4.0898e+01, -1.6337e+02, -6.3364e+01, -1.5292e+02],\n",
      "          [ 1.7649e+02,  2.6509e+02, -2.9412e+02, -1.3096e+02, -2.5859e+02]]]])\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 當我們把 parameters 的 requires_grad關閉時，就無法成功的完成backward\n",
    "* 什麼時候會關閉requires_grad關閉時？ prediction (inference)的階段\n",
    "* 設定 requires_grad = True 是為了之後要做 backpropagation，在計算每個paramters的 gradient時，我們在forward propagation時需要保留額外的訊息(根據chain rule)，這會導致記憶體使用量上升與計算速度下降，然而只有在 training 階段時我們材需要做backpropagation，在 prediction (inference)的階段，我們則可以設定 requires_grad = False 來提升速度與降低記憶體使用量 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.randn(1,1,124,124)\n",
    "output = model(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d36a7f9dc350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "output.sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with torch.no_grad()\n",
    "* 此行底下的requires_grad都會關閉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-1f483c7eca92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minput_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m124\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m124\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "with torch.no_grad():\n",
    "    input_ = torch.randn(1,1,124,124)\n",
    "    output = model(input_)\n",
    "    output.sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讓我們自行搭建一個 nn.Module 並試算gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.x = torch.nn.Parameter(torch.tensor(2.4,dtype=torch.float32))\n",
    "        self.y = torch.nn.Parameter(torch.tensor(4.3,dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x*self.x**2 + x*self.y + x # 可以看成 output = w*x*x + w*y+2\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.x 的 gradient : 6.240000247955322\n",
      "self.y 的 gradient : 1.2999999523162842\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "input_ = torch.tensor(1.3, dtype = torch.float32)\n",
    "output = model(input_)\n",
    "output.backward()\n",
    "# output 對 self.x 的偏微分為 2 * w * x = 2 * 1.3 * 2.4 = 6.24 \n",
    "print('self.x 的 gradient : {}'.format(model.x.grad))\n",
    "# output 對 self.y 的偏微分為 w = 1.3\n",
    "print('self.y 的 gradient : {}'.format(model.y.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential\n",
    "* nn.Module 的容器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Sequential(\n",
    "                        nn.Conv2d(3,\n",
    "                                  20,\n",
    "                                  kernel_size=3,\n",
    "                                  stride=1,\n",
    "                                  padding=1,\n",
    "                                  bias=False), \n",
    "                        nn.BatchNorm2d(20),\n",
    "                        nn.LeakyReLU(inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight True\n",
      "1.weight True\n",
      "1.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in layer.named_parameters():\n",
    "    print(name,param.requires_grad)\n",
    "    #param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.randn(1, 3, 124, 124)\n",
    "output = layer(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OrderedDict+Sequential, 讓我們替每一個module命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv2d(1,20,5)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv2d(20,64,5)),\n",
    "          ('relu2', nn.ReLU())\n",
    "        ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      ")\n",
      "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "ReLU()\n",
      "Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "ReLU()\n"
     ]
    }
   ],
   "source": [
    "for module in layer.modules():\n",
    "    print(module)\n",
    "    #param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight True\n",
      "conv1.bias True\n",
      "conv2.weight True\n",
      "conv2.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in layer.named_parameters():\n",
    "    print(name,param.requires_grad)\n",
    "    #param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 116, 116])\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randn(1, 1, 124, 124)\n",
    "output = layer(input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### append 新的 module到 sequential上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "modules = []\n",
    "modules.append(nn.Conv2d(1,20,5))\n",
    "modules.append(nn.ReLU())\n",
    "modules.append(nn.Conv2d(20,64,5))\n",
    "modules.append(nn.ReLU())\n",
    "\n",
    "layer = nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 116, 116])\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randn(1, 1, 124, 124)\n",
    "output = layer(input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 另一種方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = torch.nn.Sequential()\n",
    "layer.add_module(\"conv1\", nn.Conv2d(1,20,5))\n",
    "layer.add_module(\"relu1\", nn.ReLU())\n",
    "layer.add_module(\"conv2\", nn.Conv2d(20,64,5))\n",
    "layer.add_module(\"relu2\", nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 116, 116])\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randn(1, 1, 124, 124)\n",
    "output = layer(input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModuleList\n",
    "* 操作就像是python list, 但其內的module, parameters是可以被追蹤的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.ModuleList()\n",
    "layer.append(nn.Conv2d(1,20,5))\n",
    "layer.append(nn.ReLU())\n",
    "layer.append(nn.Conv2d(20,64,5))\n",
    "layer.append(nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 116, 116])\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randn(1, 1, 124, 124)\n",
    "for _, module in enumerate(layer):\n",
    "    if _ == 0:\n",
    "        output = module(input_)\n",
    "    else:\n",
    "        output = module(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 可以追蹤是什麼意思？ nn.Module有辦法去獲取ModuleList裡面的資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer = nn.ModuleList()\n",
    "        self.layer.append(nn.Conv2d(1,20,5))\n",
    "        self.layer.append(nn.ReLU())\n",
    "        self.layer.append(nn.Conv2d(20,64,5))\n",
    "        self.layer.append(nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for module in self.layer:\n",
    "            x = module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer): ModuleList(\n",
       "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 116, 116])\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randn(1, 1, 124, 124)\n",
    "output = model(input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如果是一般的 python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer = []\n",
    "        self.layer.append(nn.Conv2d(1,20,5))\n",
    "        self.layer.append(nn.ReLU())\n",
    "        self.layer.append(nn.Conv2d(20,64,5))\n",
    "        self.layer.append(nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for module in self.layer:\n",
    "            x = module(x)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
